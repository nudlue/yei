<!DOCTYPE html>
<html lang="ko">
<head>
  <meta charset="UTF-8" />
  <title>Sound Classifier Demo</title>
  <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@3.20.0/dist/tf.min.js"></script>
  <style>
    body { font-family: sans-serif; text-align: center; padding: 40px; }
    button { padding: 12px 24px; font-size: 20px; }
    #result { margin-top: 30px; font-size: 30px; }
    #emoji { font-size: 80px; margin-top: 10px; }
  </style>
</head>

<body>
  <h1>ğŸ”Š ì‹¤ì‹œê°„ ì†Œë¦¬ ë¶„ë¥˜ê¸°</h1>
  <button id="startBtn">ë…¹ìŒ ì‹œì‘</button>

  <div id="result">ëŒ€ê¸° ì¤‘...</div>
  <div id="emoji">ğŸ˜¶</div>

  <script>
    let model;
    let listening = false;
    let audioContext, analyser, microphone, dataArray;

    const labels = ["Baby Crying", "Doorbell", "Fire Alarm", "ë°°ê²½ ì†ŒìŒ"];
    const emojis = {
      "Baby Crying": "ğŸ‘¶ğŸ˜­",
      "Doorbell": "ğŸšªğŸ””",
      "Fire Alarm": "ğŸ”¥ğŸš¨",
      "ë°°ê²½ ì†ŒìŒ": "ğŸŒ«ï¸"
    };

    async function loadModel() {
      model = await tf.loadLayersModel("model.json");
      console.log("Model loaded!");
    }

    async function startRecording() {
      if (listening) return;
      listening = true;

      audioContext = new AudioContext();
      const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
      microphone = audioContext.createMediaStreamSource(stream);

      analyser = audioContext.createAnalyser();
      analyser.fftSize = 1024;
      dataArray = new Float32Array(analyser.fftSize);
      microphone.connect(analyser);

      loop();
    }

    async function loop() {
      analyser.getFloatTimeDomainData(dataArray);

      // ëª¨ë¸ ì…ë ¥ í¬ê¸° (model.json í™•ì¸ ê²°ê³¼): [43, 232, 1]
      let input = tf.tensor(dataArray).slice([0], [996]); 
      input = tf.signal.stft(input, 256, 128);           
      input = tf.abs(input).expandDims(-1);              
      input = tf.image.resizeBilinear(input, [43, 232]); 
      input = input.expandDims(0);                       

      const prediction = model.predict(input);
      const scores = await prediction.data();
      const idx = scores.indexOf(Math.max(...scores));

      updateUI(labels[idx]);

      requestAnimationFrame(loop);
    }

    function updateUI(label) {
      document.getElementById("result").innerText = `ì¸ì‹ ê²°ê³¼: ${label}`;
      document.getElementById("emoji").innerText = emojis[label];
    }

    document.getElementById("startBtn").onclick = startRecording;

    loadModel();
  </script>
</body>
</html>
